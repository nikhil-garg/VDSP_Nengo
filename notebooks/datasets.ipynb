{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-05-15 10:58:36--  http://www.di.ens.fr/~lelarge/MNIST.tar.gz\n",
      "Resolving www.di.ens.fr (www.di.ens.fr)... 129.199.99.14\n",
      "Connecting to www.di.ens.fr (www.di.ens.fr)|129.199.99.14|:80... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://www.di.ens.fr/~lelarge/MNIST.tar.gz [following]\n",
      "--2021-05-15 10:58:37--  https://www.di.ens.fr/~lelarge/MNIST.tar.gz\n",
      "Connecting to www.di.ens.fr (www.di.ens.fr)|129.199.99.14|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: unspecified [application/x-gzip]\n",
      "Saving to: ‘MNIST.tar.gz’\n",
      "\n",
      "MNIST.tar.gz            [           <=>      ]  33.20M  2.99MB/s    in 12s     \n",
      "\n",
      "2021-05-15 10:58:50 (2.73 MB/s) - ‘MNIST.tar.gz’ saved [34813078]\n",
      "\n",
      "x MNIST/\n",
      "x MNIST/raw/\n",
      "x MNIST/raw/train-labels-idx1-ubyte\n",
      "x MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
      "x MNIST/raw/t10k-labels-idx1-ubyte\n",
      "x MNIST/raw/t10k-images-idx3-ubyte.gz\n",
      "x MNIST/raw/train-images-idx3-ubyte\n",
      "x MNIST/raw/train-labels-idx1-ubyte.gz\n",
      "x MNIST/raw/t10k-images-idx3-ubyte\n",
      "x MNIST/raw/train-images-idx3-ubyte.gz\n",
      "x MNIST/processed/\n",
      "x MNIST/processed/training.pt\n",
      "x MNIST/processed/test.pt\n"
     ]
    }
   ],
   "source": [
    "!wget www.di.ens.fr/~lelarge/MNIST.tar.gz\n",
    "!tar -zxvf MNIST.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = (x_test/255-0.1308)/0.3088\n",
    "x_train = (x_train/255-0.1308)/0.3088\n",
    "x_test = 255*(x_test-x_test.min())/(x_test.max()-x_test.min())\n",
    "x_train = 255*(x_train-x_train.min())/(x_train.max()-x_train.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "np.savez_compressed('mnist_norm.npz',image_train_filtered=x_train,label_train_filtered=y_train,image_test_filtered=x_test,label_test_filtered=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "array = np.ones(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.,  0.,  0.,  0.,  0., 10.,  0.,  0.,  0.,  0.]),\n",
       " array([0.5, 0.6, 0.7, 0.8, 0.9, 1. , 1.1, 1.2, 1.3, 1.4, 1.5]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "fmnist = tf.keras.datasets.fashion_mnist\n",
    "(x_train, y_train), (x_test, y_test) = fmnist.load_data()\n",
    "np.savez_compressed('fmnist_norm.npz',image_train_filtered=x_train,label_train_filtered=y_train,image_test_filtered=x_test,label_test_filtered=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Dataset not found. You can use download=True to download it",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-4d132247d0f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m                              ])\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrainset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMNIST\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mtestset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMNIST\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownload\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtrainloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m60000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, train, transform, target_transform, download)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_exists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m             raise RuntimeError('Dataset not found.' +\n\u001b[0m\u001b[1;32m     74\u001b[0m                                ' You can use download=True to download it')\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Dataset not found. You can use download=True to download it"
     ]
    }
   ],
   "source": [
    "transform=transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.1308,), (0.3088,) )\n",
    "                             ])\n",
    "\n",
    "trainset = datasets.MNIST(root='./data', train=True, download=False, transform=transform)\n",
    "testset = datasets.MNIST(root='./data', train=False, download=False, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=60000, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=10000, shuffle=True)\n",
    "dataiter_train = iter(trainloader) # creating a iterator\n",
    "images_train, labels_train = dataiter_train.next()\n",
    "dataiter_test = iter(testloader) # creating a iterator\n",
    "images_test, labels_test = dataiter_test.next()\n",
    "\n",
    "images_train = (images_train - images_train.min())/(images_train.max()-images_train.min())\n",
    "images_test = (images_test - images_test.min())/(images_test.max()-images_test.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Dataset not found. You can use download=True to download it",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-173b5413eb59>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m train_loader = torch.utils.data.DataLoader(\n\u001b[0;32m----> 2\u001b[0;31m   torchvision.datasets.MNIST(root='./data',train=True, download=False,\n\u001b[0m\u001b[1;32m      3\u001b[0m                              transform=torchvision.transforms.Compose([\n\u001b[1;32m      4\u001b[0m                                \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mToTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                torchvision.transforms.Normalize(\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, train, transform, target_transform, download)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_exists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m             raise RuntimeError('Dataset not found.' +\n\u001b[0m\u001b[1;32m     74\u001b[0m                                ' You can use download=True to download it')\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Dataset not found. You can use download=True to download it"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST(root='./data',train=True, download=False,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=60000, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST( root='./data',train=False, download=False,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=10000, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'images_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-f311b57efb8b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimages_test\u001b[0m \u001b[0;34m*=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mimages_train\u001b[0m \u001b[0;34m*=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'images_test' is not defined"
     ]
    }
   ],
   "source": [
    "images_test *=256\n",
    "images_train *=256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_test = np.array(images_test)\n",
    "images_train = np.array(images_train)\n",
    "images_train = images_train[:,0,:,:]\n",
    "images_test = images_test[:,0,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images_test = images_test.astype(int)\n",
    "# images_train = images_train.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed('qmnist_norm.npz',image_train_filtered=images_train,label_train_filtered=labels_train,image_test_filtered=images_test,label_test_filtered=labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('qmnist.npz', allow_pickle=True)\n",
    "image_test_filtered = data['image_test_filtered']\n",
    "label_test_filtered = data['label_test_filtered']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_test_filtered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = images_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13083333"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_train.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30880386"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# images_train.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fashion MNIST\n",
    "\n",
    "transform=transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.2859,), (0.3530,) )\n",
    "                             ])\n",
    "\n",
    "trainset = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
    "testset = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=60000, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=60000, shuffle=True)\n",
    "dataiter_train = iter(trainloader) # creating a iterator\n",
    "images_train, labels_train = dataiter_train.next()\n",
    "dataiter_test = iter(testloader) # creating a iterator\n",
    "images_test, labels_test = dataiter_test.next()\n",
    "\n",
    "images_train = (images_train - images_train.min())/(images_train.max()-images_train.min())\n",
    "images_test = (images_test - images_test.min())/(images_test.max()-images_test.min())\n",
    "\n",
    "images_test *=256\n",
    "images_train *=256\n",
    "\n",
    "images_test = np.array(images_test)\n",
    "images_train = np.array(images_train)\n",
    "images_train = images_train[:,0,:,:]\n",
    "images_test = images_test[:,0,:,:]\n",
    "\n",
    "np.savez_compressed('fmnist_norm.npz',image_train_filtered=images_train,label_train_filtered=labels_train,image_test_filtered=images_test,label_test_filtered=labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_train.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
